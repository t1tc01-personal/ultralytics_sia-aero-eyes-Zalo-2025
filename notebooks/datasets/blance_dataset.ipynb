{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd625814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dad3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_subset(\n",
    "    dataset_root,\n",
    "    output_root,\n",
    "    train_samples=4000,\n",
    "    val_samples=1000,\n",
    "    negative_ratio=0.25,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    T·∫°o subset c√¢n b·∫±ng t·ª´ dataset g·ªëc\n",
    "    \n",
    "    Args:\n",
    "        dataset_root: ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset g·ªëc (dataset_output)\n",
    "        output_root: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u subset m·ªõi\n",
    "        train_samples: S·ªë l∆∞·ª£ng samples cho train (3500)\n",
    "        val_samples: S·ªë l∆∞·ª£ng samples cho val (500)\n",
    "        negative_ratio: T·ªâ l·ªá negative samples (0.25 = 25%)\n",
    "        seed: Random seed\n",
    "    \n",
    "    Strategy \"C√¢n b·∫±ng\":\n",
    "    - Perfectly balanced: M·ªói class c√≥ s·ªë l∆∞·ª£ng samples b·∫±ng nhau\n",
    "    - N·∫øu m·ªôt class kh√¥ng ƒë·ªß samples, l·∫•y t·∫•t c·∫£ v√† ph√¢n b·ªï l·∫°i cho c√°c class kh√°c\n",
    "    - Negative samples ƒë∆∞·ª£c l·∫•y ng·∫´u nhi√™n t·ª´ t·∫•t c·∫£ negative samples\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    dataset_root = Path(dataset_root)\n",
    "    output_root = Path(output_root)\n",
    "    \n",
    "    # Load class names\n",
    "    with open(dataset_root / 'data.yaml', 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        class_names = data.get('names', [])\n",
    "        num_classes = data.get('nc', len(class_names))\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìä T·∫†O BALANCED SUBSET\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    print(f\"Train samples: {train_samples} (25% negative = {int(train_samples * negative_ratio)})\")\n",
    "    print(f\"Val samples: {val_samples} (25% negative = {int(val_samples * negative_ratio)})\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # T√≠nh to√°n s·ªë l∆∞·ª£ng samples cho m·ªói class\n",
    "    train_positive = int(train_samples * (1 - negative_ratio))  # 2625\n",
    "    val_positive = int(val_samples * (1 - negative_ratio))      # 375\n",
    "    train_negative = train_samples - train_positive              # 875\n",
    "    val_negative = val_samples - val_positive                    # 125\n",
    "    \n",
    "    samples_per_class_train = train_positive // num_classes     # ~375\n",
    "    samples_per_class_val = val_positive // num_classes          # ~53\n",
    "    \n",
    "    print(f\"\\nüìà Ph√¢n b·ªï:\")\n",
    "    print(f\"Train - Positive: {train_positive} ({samples_per_class_train}/class)\")\n",
    "    print(f\"Train - Negative: {train_negative}\")\n",
    "    print(f\"Val - Positive: {val_positive} ({samples_per_class_val}/class)\")\n",
    "    print(f\"Val - Negative: {val_negative}\")\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c output\n",
    "    for split in ['train', 'val']:\n",
    "        (output_root / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (output_root / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # X·ª≠ l√Ω t·ª´ng split\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üîÑ X·ª≠ l√Ω {split.upper()}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        images_dir = dataset_root / split / 'images'\n",
    "        labels_dir = dataset_root / split / 'labels'\n",
    "        \n",
    "        # ƒê·ªçc t·∫•t c·∫£ images\n",
    "        image_files = list(images_dir.glob('*.tif'))\n",
    "        print(f\"T·ªïng s·ªë images: {len(image_files)}\")\n",
    "        \n",
    "        # Ph√¢n lo·∫°i samples\n",
    "        positive_by_class = defaultdict(list)  # {class_id: [image_paths]}\n",
    "        negative_samples = []  # [image_paths]\n",
    "        \n",
    "        for img_path in tqdm(image_files, desc=f\"Ph√¢n lo·∫°i {split}\"):\n",
    "            label_path = labels_dir / (img_path.stem + '.txt')\n",
    "            \n",
    "            if not label_path.exists() or label_path.stat().st_size == 0:\n",
    "                # Negative sample (kh√¥ng c√≥ label ho·∫∑c label r·ªóng)\n",
    "                negative_samples.append(img_path)\n",
    "            else:\n",
    "                # Positive sample - ƒë·ªçc classes trong label\n",
    "                with open(label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    classes_in_image = set()\n",
    "                    for line in lines:\n",
    "                        if line.strip():\n",
    "                            class_id = int(line.strip().split()[0])\n",
    "                            classes_in_image.add(class_id)\n",
    "                    \n",
    "                    # Th√™m v√†o t·∫•t c·∫£ classes c√≥ trong image\n",
    "                    for class_id in classes_in_image:\n",
    "                        positive_by_class[class_id].append(img_path)\n",
    "        \n",
    "        print(f\"\\nüìä Th·ªëng k√™ {split}:\")\n",
    "        print(f\"Negative samples: {len(negative_samples)}\")\n",
    "        for class_id in range(num_classes):\n",
    "            unique_samples = len(set(positive_by_class[class_id]))\n",
    "            print(f\"Class {class_id} ({class_names[class_id]}): {unique_samples} samples\")\n",
    "        \n",
    "        # Sample c√¢n b·∫±ng\n",
    "        target_samples = train_samples if split == 'train' else val_samples\n",
    "        target_positive = train_positive if split == 'train' else val_positive\n",
    "        target_negative = train_negative if split == 'train' else val_negative\n",
    "        samples_per_class = samples_per_class_train if split == 'train' else samples_per_class_val\n",
    "        \n",
    "        selected_images = []\n",
    "        selected_labels = []\n",
    "        \n",
    "        # 1. Sample t·ª´ m·ªói class (c√¢n b·∫±ng)\n",
    "        print(f\"\\nüéØ Sampling t·ª´ m·ªói class ({samples_per_class}/class)...\")\n",
    "        class_counts = {}\n",
    "        \n",
    "        for class_id in range(num_classes):\n",
    "            class_samples = list(set(positive_by_class[class_id]))  # Remove duplicates\n",
    "            random.shuffle(class_samples)\n",
    "            \n",
    "            # L·∫•y samples_per_class ho·∫∑c t·∫•t c·∫£ n·∫øu kh√¥ng ƒë·ªß\n",
    "            num_to_sample = min(samples_per_class, len(class_samples))\n",
    "            selected = class_samples[:num_to_sample]\n",
    "            \n",
    "            class_counts[class_id] = len(selected)\n",
    "            print(f\"  Class {class_id} ({class_names[class_id]}): {len(selected)}/{len(class_samples)}\")\n",
    "            \n",
    "            for img_path in selected:\n",
    "                if img_path not in selected_images:  # Tr√°nh duplicate\n",
    "                    selected_images.append(img_path)\n",
    "        \n",
    "        # 2. N·∫øu thi·∫øu samples, ph√¢n b·ªï l·∫°i t·ª´ c√°c class c√≤n d∆∞\n",
    "        current_positive = len(selected_images)\n",
    "        if current_positive < target_positive:\n",
    "            print(f\"\\n‚ö†Ô∏è  Thi·∫øu {target_positive - current_positive} positive samples, ph√¢n b·ªï l·∫°i...\")\n",
    "            remaining_needed = target_positive - current_positive\n",
    "            \n",
    "            # T√¨m c√°c class c√≤n d∆∞ samples\n",
    "            available_samples = []\n",
    "            for class_id in range(num_classes):\n",
    "                class_samples = list(set(positive_by_class[class_id]))\n",
    "                already_selected = [img for img in selected_images if img in class_samples]\n",
    "                remaining = [img for img in class_samples if img not in already_selected]\n",
    "                available_samples.extend(remaining)\n",
    "            \n",
    "            random.shuffle(available_samples)\n",
    "            additional = available_samples[:remaining_needed]\n",
    "            selected_images.extend(additional)\n",
    "            print(f\"  ƒê√£ th√™m {len(additional)} samples t·ª´ c√°c class c√≤n d∆∞\")\n",
    "        \n",
    "        # 3. Sample negative samples\n",
    "        print(f\"\\nüéØ Sampling negative samples ({target_negative})...\")\n",
    "        random.shuffle(negative_samples)\n",
    "        selected_negative = negative_samples[:target_negative]\n",
    "        selected_images.extend(selected_negative)\n",
    "        \n",
    "        print(f\"\\n‚úÖ ƒê√£ ch·ªçn {len(selected_images)} samples:\")\n",
    "        print(f\"  - Positive: {len(selected_images) - len(selected_negative)}\")\n",
    "        print(f\"  - Negative: {len(selected_negative)}\")\n",
    "        print(f\"  - Ph√¢n b·ªï theo class:\")\n",
    "        for class_id in range(num_classes):\n",
    "            count = sum(1 for img in selected_images[:len(selected_images)-len(selected_negative)]\n",
    "                       if img in positive_by_class[class_id])\n",
    "            print(f\"    Class {class_id} ({class_names[class_id]}): {count}\")\n",
    "        \n",
    "        # 4. Copy files\n",
    "        print(f\"\\nüìÅ Copying files...\")\n",
    "        for img_path in tqdm(selected_images, desc=f\"Copy {split}\"):\n",
    "            # Copy image\n",
    "            dst_img = output_root / split / 'images' / img_path.name\n",
    "            shutil.copy2(img_path, dst_img)\n",
    "            \n",
    "            # Copy label (n·∫øu c√≥)\n",
    "            label_path = labels_dir / (img_path.stem + '.txt')\n",
    "            if label_path.exists() and label_path.stat().st_size > 0:\n",
    "                dst_label = output_root / split / 'labels' / label_path.name\n",
    "                shutil.copy2(label_path, dst_label)\n",
    "    \n",
    "    # Copy data.yaml\n",
    "    shutil.copy2(dataset_root / 'data.yaml', output_root / 'data.yaml')\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Output: {output_root}\")\n",
    "    print(f\"Train: {len(list((output_root / 'train' / 'images').glob('*.tif')))} samples\")\n",
    "    print(f\"Val: {len(list((output_root / 'val' / 'images').glob('*.tif')))} samples\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65df769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä T·∫†O BALANCED SUBSET\n",
      "======================================================================\n",
      "Classes: ['Backpack', 'Jacket', 'Laptop', 'Lifering', 'Mobilephone', 'Person1', 'WaterBottle']\n",
      "Train samples: 3500 (25% negative = 875)\n",
      "Val samples: 500 (25% negative = 125)\n",
      "======================================================================\n",
      "\n",
      "üìà Ph√¢n b·ªï:\n",
      "Train - Positive: 2625 (375/class)\n",
      "Train - Negative: 875\n",
      "Val - Positive: 375 (53/class)\n",
      "Val - Negative: 125\n",
      "\n",
      "======================================================================\n",
      "üîÑ X·ª≠ l√Ω TRAIN\n",
      "======================================================================\n",
      "T·ªïng s·ªë images: 18646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ph√¢n lo·∫°i train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18646/18646 [00:06<00:00, 2985.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Th·ªëng k√™ train:\n",
      "Negative samples: 3726\n",
      "Class 0 (Backpack): 4638 samples\n",
      "Class 1 (Jacket): 1852 samples\n",
      "Class 2 (Laptop): 1871 samples\n",
      "Class 3 (Lifering): 2645 samples\n",
      "Class 4 (Mobilephone): 1857 samples\n",
      "Class 5 (Person1): 2057 samples\n",
      "Class 6 (WaterBottle): 0 samples\n",
      "\n",
      "üéØ Sampling t·ª´ m·ªói class (375/class)...\n",
      "  Class 0 (Backpack): 375/4638\n",
      "  Class 1 (Jacket): 375/1852\n",
      "  Class 2 (Laptop): 375/1871\n",
      "  Class 3 (Lifering): 375/2645\n",
      "  Class 4 (Mobilephone): 375/1857\n",
      "  Class 5 (Person1): 375/2057\n",
      "  Class 6 (WaterBottle): 0/0\n",
      "\n",
      "‚ö†Ô∏è  Thi·∫øu 375 positive samples, ph√¢n b·ªï l·∫°i...\n",
      "  ƒê√£ th√™m 375 samples t·ª´ c√°c class c√≤n d∆∞\n",
      "\n",
      "üéØ Sampling negative samples (875)...\n",
      "\n",
      "‚úÖ ƒê√£ ch·ªçn 3500 samples:\n",
      "  - Positive: 2625\n",
      "  - Negative: 875\n",
      "  - Ph√¢n b·ªï theo class:\n",
      "    Class 0 (Backpack): 506\n",
      "    Class 1 (Jacket): 421\n",
      "    Class 2 (Laptop): 422\n",
      "    Class 3 (Lifering): 432\n",
      "    Class 4 (Mobilephone): 422\n",
      "    Class 5 (Person1): 422\n",
      "    Class 6 (WaterBottle): 0\n",
      "\n",
      "üìÅ Copying files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copy train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1153/3500 [00:18<00:36, 63.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcreate_balanced_subset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/t1tc01-hoangphan/code/t1tc01-personal/ultralytics_sia-aero-eyes-Zalo-2025/dataset_output\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_root\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/t1tc01-hoangphan/code/t1tc01-personal/ultralytics_sia-aero-eyes-Zalo-2025/dataset_output_balanced\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mcreate_balanced_subset\u001b[39m\u001b[34m(dataset_root, output_root, train_samples, val_samples, negative_ratio, seed)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(selected_images, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCopy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# Copy image\u001b[39;00m\n\u001b[32m    174\u001b[39m     dst_img = output_root / split / \u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m / img_path.name\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# Copy label (n·∫øu c√≥)\u001b[39;00m\n\u001b[32m    178\u001b[39m     label_path = labels_dir / (img_path.stem + \u001b[33m'\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:475\u001b[39m, in \u001b[36mcopy2\u001b[39m\u001b[34m(src, dst, follow_symlinks)\u001b[39m\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    473\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m copystat(src, dst, follow_symlinks=follow_symlinks)\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:273\u001b[39m, in \u001b[36mcopyfile\u001b[39m\u001b[34m(src, dst, follow_symlinks)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _USE_CP_SENDFILE:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m         \u001b[43m_fastcopy_sendfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _GiveupOnFastCopy:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:150\u001b[39m, in \u001b[36m_fastcopy_sendfile\u001b[39m\u001b[34m(fsrc, fdst)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         sent = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    152\u001b[39m         \u001b[38;5;66;03m# ...in oder to have a more informative exception.\u001b[39;00m\n\u001b[32m    153\u001b[39m         err.filename = fsrc.name\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "create_balanced_subset(\n",
    "    dataset_root='/home/t1tc01-hoangphan/code/t1tc01-personal/ultralytics_sia-aero-eyes-Zalo-2025/dataset_output',\n",
    "    output_root='/home/t1tc01-hoangphan/code/t1tc01-personal/ultralytics_sia-aero-eyes-Zalo-2025/dataset_output_balanced',\n",
    "    train_samples=4000,\n",
    "    val_samples=1000,\n",
    "    negative_ratio=0.25,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90190f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
